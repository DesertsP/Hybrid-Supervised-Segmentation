misc:
  log_freq: 40
  verbose: 1
  debug: false
  resume: ''
  eval_freq: 1
  seed: 2
train:
  num_epochs: 80
  batch_size: 8
  batch_size_unsup: 24
  indicator_batch_size: 32
  indicator_update_from_iter: 400
  indicator_update_freq: 400
  num_workers: 8
  loss_coefficient:
    seg_loss: 0.5
    reg_loss: 1.5
    cl_loss: 1.5
  optimizer:
    name: torch.optim.SGD
    lr: 0.001
    momentum: 0.9
    weight_decay: 0.0001
  lr_scheduler:
    name: utils.lr_helper.LRScheduler
    mode: poly
    lr_args:
      power: 0.9
  indicator_optimizer:
    name: utils.custom_optm.AdamWeightUpdate
    lr: 0.1
    clamp_max: 2.0
    clamp_min: 0.0
trainset:
  name: datasets.voc_v5_idx.voc_trainset
  root: /workspace/data/VOC2012
  split: /workspace/data/splits/pascal/92/labeled.txt
valset:
  name: datasets.voc_v5_idx.voc_valset
  root: /workspace/data/VOC2012
  split: /workspace/data/splits/pascal/val.txt
model:
  name: models.region_indicator_learner_acc_cl.MeanTeacherLearner
  num_classes: 21
  indicator_initialization: 0.5
  num_samples: 10582
  ema_decay: 0.99
  pseudo_augment: cutmix
  pseudo_keep_ratio: 100
  pseudo_augment_prob: 1.0
  network_cfg:
    name: models.deeplab2_repr.DeepLab
    num_classes: 21
    repr_channels: 256
    backbone_cfg:
      name: models.backbones.resnet.resnet101
      pretrained: /workspace/pretrained/resnet101.pth
      replace_stride_with_dilation: [false, true, true]
      zero_init_residual: true
      multi_grid: true
    decoder_cfg:
      name: models.mods.aspp.ASPPDecoder
    norm_cfg:
      name: torch.nn.SyncBatchNorm
